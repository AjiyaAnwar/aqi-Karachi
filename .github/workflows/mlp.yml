name: AQI Karachi ML Pipeline - PRODUCTION ENHANCED

on:
  schedule:
    # Hourly feature updates (as required)
    - cron: '0 */1 * * *'
    
    # 3-hourly data collection (0, 3, 6, 9, 12, 15, 18, 21 UTC)
    - cron: '0 */3 * * *'
    
    # Daily training at 2 AM UTC
    - cron: '0 2 * * *'
    
    # Weekly full pipeline Sunday at 5 AM UTC
    - cron: '0 5 * * 0'
  
  workflow_dispatch:
    inputs:
      pipeline_step:
        description: 'Select pipeline step to run'
        required: false
        default: 'full'
        type: choice
        options:
          - data_incremental
          - data_full
          - features
          - train_combined
          - predictions
          - alerts_check
          - full
  
  push:
    branches: [main]
    paths:
      - 'aqi-karachi/**'
      - '.github/workflows/**'

jobs:
  execute-pipeline:
    runs-on: ubuntu-latest
    timeout-minutes: 60
    
    env:
      MONGODB_URI: ${{ secrets.MONGODB_URI }}
      MONGODB_DATABASE: aqi_predictor
      FEATURE_STORE_DB: aqi_feature_store
      MODEL_REGISTRY_DB: aqi_model_registry
      LOGS_DB: aqi_pipeline_logs
      
      CITY_NAME: Karachi
      CITY_LAT: 24.8607
      CITY_LON: 67.0011
      TIMEZONE: Asia/Karachi
      
      GITHUB_ACTIONS: true
      PYTHONPATH: ${{ github.workspace }}/aqi-karachi:${{ github.workspace }}
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
    
    - name: Setup Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.10'
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install pymongo python-dotenv pandas scikit-learn joblib
        pip install streamlit plotly
        pip install xgboost
        pip install prophet
        pip install requests
        pip install scipy
        echo "‚úÖ Dependencies installed"
    
    - name: Log pipeline start
      run: |
        echo "üöÄ Starting AQI Karachi Pipeline"
        echo "Event: ${{ github.event_name }}"
        echo "Time: $(date '+%Y-%m-%d %H:%M:%S %Z')"
        echo "Time Karachi: $(TZ='Asia/Karachi' date '+%Y-%m-%d %H:%M:%S %Z')"
    
    - name: Determine pipeline step
      id: determine_step
      run: |
        echo "üîç Determining pipeline step..."
        
        if [[ "${{ github.event_name }}" == "workflow_dispatch" ]]; then
          STEP="${{ github.event.inputs.pipeline_step }}"
          echo "Manual trigger, step: $STEP"
          echo "step=$STEP" >> $GITHUB_OUTPUT
          
        elif [[ "${{ github.event_name }}" == "schedule" ]]; then
          HOUR=$(date -u +%H)
          DAY=$(date -u +%u)
          MINUTE=$(date -u +%M)
          
          echo "Schedule trigger - Hour: $HOUR, Day: $DAY, Minute: $MINUTE"
          
          # Every hour: features
          if [[ $MINUTE == "00" ]]; then
            echo "Running hourly feature engineering"
            echo "step=features" >> $GITHUB_OUTPUT
          
          # Every 3 hours: data collection + predictions
          elif [[ $HOUR == "00" ]] || [[ $HOUR == "03" ]] || [[ $HOUR == "06" ]] || \
               [[ $HOUR == "09" ]] || [[ $HOUR == "12" ]] || [[ $HOUR == "15" ]] || \
               [[ $HOUR == "18" ]] || [[ $HOUR == "21" ]]; then
            echo "Running 3-hourly data collection and predictions"
            echo "step=predictions" >> $GITHUB_OUTPUT
          
          # Daily at 2 AM: training
          elif [[ $HOUR == "02" ]]; then
            echo "Running daily training"
            echo "step=train_combined" >> $GITHUB_OUTPUT
          
          # Sunday at 5 AM: full pipeline
          elif [[ $HOUR == "05" ]] && [[ $DAY == "7" ]]; then
            echo "Running full pipeline (Sunday)"
            echo "step=full" >> $GITHUB_OUTPUT
          
          else
            echo "step=skip" >> $GITHUB_OUTPUT
          fi
          
        else
          echo "Push event, running full pipeline"
          echo "step=full" >> $GITHUB_OUTPUT
        fi
    
    - name: Execute Data Collection (Incremental)
      if: steps.determine_step.outputs.step == 'data_incremental' || steps.determine_step.outputs.step == 'predictions'
      run: |
        echo "üöÄ Running incremental data collection..."
        cd aqi-karachi
        export PYTHONPATH="$PYTHONPATH:$(pwd)"
        python data_pipeline/fetch_incremental.py
        
        # Log completion
        echo "‚úÖ Data collection completed at $(date '+%Y-%m-%d %H:%M:%S UTC')"
    
    - name: Execute Data Collection (Full)
      if: steps.determine_step.outputs.step == 'data_full'
      run: |
        echo "üöÄ Running full data collection..."
        cd aqi-karachi
        export PYTHONPATH="$PYTHONPATH:$(pwd)"
        python data_pipeline/collect_historical.py
        
        # Log completion
        echo "‚úÖ Full data collection completed at $(date '+%Y-%m-%d %H:%M:%S UTC')"
    
    - name: Execute Feature Engineering (Hourly)
      if: steps.determine_step.outputs.step == 'features'
      run: |
        echo "üöÄ Running hourly feature engineering..."
        cd aqi-karachi
        export PYTHONPATH="$PYTHONPATH:$(pwd)"
        python data_pipeline/features.py
        
        # Log completion
        echo "‚úÖ Feature engineering completed at $(date '+%Y-%m-%d %H:%M:%S UTC')"
    
    - name: Execute Model Training
      if: steps.determine_step.outputs.step == 'train_combined'
      run: |
        echo "üöÄ Running model training and predictions..."
        cd aqi-karachi
        export PYTHONPATH="$PYTHONPATH:$(pwd)"
        python model_training/runallmodels.py
        
        # Log completion
        echo "‚úÖ Model training completed at $(date '+%Y-%m-%d %H:%M:%S UTC')"
    
    - name: Generate Predictions
      if: steps.determine_step.outputs.step == 'predictions'
      run: |
        echo "üöÄ Generating fresh predictions..."
        cd aqi-karachi
        export PYTHONPATH="$PYTHONPATH:$(pwd)"
        
        # First ensure we have features
        echo "Step 1: Feature Engineering..."
        python data_pipeline/features.py
        
        # Then generate predictions
        echo "Step 2: Generating predictions..."
        python model_training/runallmodels.py --predict-only
        
        # Log completion
        echo "‚úÖ Predictions generated at $(date '+%Y-%m-%d %H:%M:%S UTC')"
    
    - name: Execute Full Pipeline
      if: steps.determine_step.outputs.step == 'full'
      run: |
        echo "üöÄ Running FULL pipeline..."
        cd aqi-karachi
        export PYTHONPATH="$PYTHONPATH:$(pwd)"
        
        echo "Step 1: Data Collection..."
        python data_pipeline/collect_historical.py
        
        echo "Step 2: Feature Engineering..."
        python data_pipeline/features.py
        
        echo "Step 3: Model Training & Predictions..."
        python model_training/runallmodels.py
        
        echo "‚úÖ Full pipeline completed at $(date '+%Y-%m-%d %H:%M:%S UTC')"
    
    - name: Log pipeline completion to MongoDB
      if: steps.determine_step.outputs.step != 'skip'
      run: |
        echo "üìù Logging pipeline completion to MongoDB..."
        cd aqi-karachi
        export PYTHONPATH="$PYTHONPATH:$(pwd)"
        
        python -c "
        from pymongo import MongoClient
        import os
        from datetime import datetime
        from dotenv import load_dotenv
        load_dotenv()
        
        client = MongoClient(os.getenv('MONGODB_URI'))
        logs_db = client.get_database('aqi_pipeline_logs')
        
        # Create collection if not exists
        if 'pipeline_logs' not in logs_db.list_collection_names():
            logs_db.create_collection('pipeline_logs')
        
        # Log this run
        logs_db.pipeline_logs.insert_one({
            'pipeline_step': '${{ steps.determine_step.outputs.step }}',
            'status': 'completed',
            'timestamp': datetime.now(),
            'github_event': '${{ github.event_name }}',
            'run_id': '${{ github.run_id }}',
            'trigger': 'schedule' if '${{ github.event_name }}' == 'schedule' else 'manual',
            'message': 'Pipeline executed successfully'
        })
        
        print('‚úÖ Pipeline logged to MongoDB')
        client.close()
        "
    
    - name: Check AQI Alerts
      if: steps.determine_step.outputs.step == 'alerts_check' || steps.determine_step.outputs.step == 'full'
      run: |
        echo "üö® Checking for hazardous AQI levels..."
        cd aqi-karachi
        export PYTHONPATH="$PYTHONPATH:$(pwd)"
        python -c "
        from pymongo import MongoClient
        import os
        from dotenv import load_dotenv
        load_dotenv()
        
        client = MongoClient(os.getenv('MONGODB_URI'))
        db = client[os.getenv('MONGODB_DATABASE', 'aqi_predictor')]
        
        latest_aqi = db.aqi_measurements.find_one(sort=[('timestamp', -1)])
        if latest_aqi:
            current_aqi = latest_aqi.get('aqi', 0)
            if current_aqi > 300:
                print('üö®üö®üö® HAZARDOUS AQI LEVEL! Immediate action required!')
            elif current_aqi > 200:
                print('‚ö†Ô∏è‚ö†Ô∏è VERY UNHEALTHY AQI! Sensitive groups avoid outdoors.')
        "
    
    - name: Auto-generate forecasts if missing - FIXED
      if: steps.determine_step.outputs.step != 'skip'
      run: |
        echo "üîç Checking if forecasts exist..."
        cd aqi-karachi
        export PYTHONPATH="$PYTHONPATH:$(pwd)"
        python -c "
        from pymongo import MongoClient
        import os
        from datetime import datetime, timedelta
        from dotenv import load_dotenv
        
        load_dotenv()
        
        client = MongoClient(os.getenv('MONGODB_URI'))
        db = client[os.getenv('MONGODB_DATABASE', 'aqi_predictor')]
        
        forecast_collections = ['ensemble_forecasts_3day', 'ml_recursive_forecasts', 'timeseries_forecasts_3day']
        has_forecasts = False
        
        for col in forecast_collections:
            if col in db.list_collection_names():
                # Check if forecasts are recent (less than 4 hours old)
                latest = db[col].find_one(sort=[('created_at', -1)])
                if latest and 'created_at' in latest:
                    # FIXED: Handle datetime object properly
                    created_at_value = latest['created_at']
                    
                    # Convert to datetime if it's a string
                    if isinstance(created_at_value, str):
                        try:
                            from dateutil import parser
                            latest_time = parser.parse(created_at_value)
                        except:
                            # If parsing fails, use current time minus 1 day
                            latest_time = datetime.now() - timedelta(days=1)
                    elif isinstance(created_at_value, datetime):
                        # Already a datetime object
                        latest_time = created_at_value
                    else:
                        # Unknown type, use fallback
                        latest_time = datetime.now() - timedelta(days=1)
                    
                    age_hours = (datetime.now() - latest_time).total_seconds() / 3600
                    
                    if age_hours < 4:
                        has_forecasts = True
                        print(f'‚úÖ Recent forecasts found in {col} ({age_hours:.1f}h old)')
                        break
        
        if not has_forecasts:
            print('‚ö†Ô∏è No recent forecasts found! Running predictions...')
            import subprocess
            try:
                # First run features
                subprocess.run(['python', 'data_pipeline/features.py'], check=True)
                # Then run predictions
                result = subprocess.run(['python', 'model_training/runallmodels.py'], check=True)
                if result.returncode == 0:
                    print('‚úÖ Predictions generated successfully')
                else:
                    print('‚ùå Failed to generate predictions')
            except Exception as e:
                print(f'‚ùå Failed to generate predictions: {e}')
        else:
            print('‚úÖ Recent forecasts exist in database')
        "
    
    - name: Update dashboard timestamp
      if: steps.determine_step.outputs.step != 'skip'
      run: |
        echo "üïí Updating dashboard timestamp marker..."
        cd aqi-karachi
        export PYTHONPATH="$PYTHONPATH:$(pwd)"
        
        python -c "
        from pymongo import MongoClient
        import os
        from datetime import datetime
        from dotenv import load_dotenv
        load_dotenv()
        
        client = MongoClient(os.getenv('MONGODB_URI'))
        db = client[os.getenv('MONGODB_DATABASE', 'aqi_predictor')]
        
        # Create/update a timestamp marker for dashboard
        db.dashboard_status.update_one(
            {'type': 'last_update'},
            {'\$set': {
                'timestamp': datetime.now(),
                'pipeline_step': '${{ steps.determine_step.outputs.step }}',
                'status': 'completed'
            }},
            upsert=True
        )
        
        print('‚úÖ Dashboard timestamp updated')
        client.close()
        "
    
    - name: Summary
      run: |
        echo "üìä PIPELINE SUMMARY"
        echo "=================="
        echo "Step executed: ${{ steps.determine_step.outputs.step }}"
        echo "Status: ${{ job.status }}"
        echo "Time UTC: $(date -u '+%Y-%m-%d %H:%M:%S UTC')"
        echo "Time Karachi: $(TZ='Asia/Karachi' date '+%Y-%m-%d %H:%M:%S %Z')"
        echo "Run ID: ${{ github.run_id }}"
        echo "Event: ${{ github.event_name }}"
        echo "=================="
        
        # Calculate next run times
        echo ""
        echo "‚è∞ NEXT SCHEDULED RUNS:"
        echo "----------------------"
        echo "Data Collection: Every 3 hours (0, 3, 6, 9, 12, 15, 18, 21 UTC)"
        echo "Predictions: Every 3 hours"
        echo "Model Training: Daily at 2 AM UTC"
        echo "Full Pipeline: Sunday at 5 AM UTC"
        echo "Dashboard Refresh: Every 5 minutes"
