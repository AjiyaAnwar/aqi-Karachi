name: AQI Karachi ML Pipeline - PRODUCTION FIXED

on:
  schedule:
    # Data collection every 3 hours
    - cron: '0 */3 * * *'
    
    # Feature engineering daily at 1 AM UTC
    - cron: '0 1 * * *'
    
    # Run YOUR combinedtraining.py twice daily (4 AM & 4 PM UTC)
    - cron: '0 4 * * *'
    - cron: '0 16 * * *'
    
    # Full pipeline every Sunday at 5 AM UTC
    - cron: '0 5 * * 0'
    
  workflow_dispatch:
    inputs:
      pipeline_step:
        description: 'Select pipeline step to run'
        required: false
        default: 'full'
        type: choice
        options:
          - data_incremental
          - data_full
          - features
          - train_combined  # CHANGED: This runs combinedtraining.py
          - predictions
          - full
    
  push:
    branches: [main]
    paths:
      - 'data_pipeline/**'
      - 'model_training/**'
      - '.github/workflows/**'
      - 'requirements.txt'

jobs:
  execute-pipeline:
    runs-on: ubuntu-latest
    timeout-minutes: 30
    environment: production
    
    env:
      MONGODB_URI: ${{ secrets.MONGODB_URI }}
      MONGODB_DATABASE: aqi_predictor
      MODEL_REGISTRY_DATABASE: aqi_model_registry
      
      CITY_NAME: Karachi
      CITY_LAT: 24.8607
      CITY_LON: 67.0011
      TIMEZONE: Asia/Karachi
      
      GITHUB_ACTIONS: true
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
    
    - name: Setup Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.10'
        cache: 'pip'
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install pymongo python-dotenv pandas numpy scikit-learn joblib
        pip install streamlit plotly  # For dashboard compatibility
    
    - name: Test MongoDB connection
      run: |
        echo "ðŸ”Œ Testing MongoDB connection..."
        python -c "
        from pymongo import MongoClient
        import os
        uri = os.getenv('MONGODB_URI')
        if uri:
            try:
                client = MongoClient(uri, serverSelectionTimeoutMS=5000)
                client.server_info()
                print('âœ… MongoDB connection successful')
            except Exception as e:
                print(f'âŒ MongoDB connection failed: {e}')
                exit(1)
        else:
            print('âŒ MONGODB_URI not set')
            exit(1)
        "
    
    - name: Determine pipeline step
      id: determine_step
      run: |
        echo "ðŸ” Determining pipeline step..."
        
        if [[ "${{ github.event_name }}" == "workflow_dispatch" ]]; then
          STEP="${{ github.event.inputs.pipeline_step }}"
          echo "Manual trigger, step: $STEP"
          echo "step=$STEP" >> $GITHUB_OUTPUT
          
        elif [[ "${{ github.event_name }}" == "schedule" ]]; then
          HOUR=$(date -u +%H)
          DAY=$(date -u +%u)
          
          echo "Scheduled trigger, UTC Hour: $HOUR, Day: $DAY"
          
          case $HOUR in
            "00"|"03"|"06"|"09"|"12"|"15"|"18"|"21")
              echo "Running incremental data collection"
              echo "step=data_incremental" >> $GITHUB_OUTPUT
              ;;
            "01")
              echo "Running feature engineering"
              echo "step=features" >> $GITHUB_OUTPUT
              ;;
            "04"|"16")
              echo "Running combined training (YOUR SCRIPT)"
              echo "step=train_combined" >> $GITHUB_OUTPUT
              ;;
            "05")
              if [[ $DAY -eq 7 ]]; then
                echo "Running full pipeline (Sunday)"
                echo "step=full" >> $GITHUB_OUTPUT
              else
                echo "Skipping (not Sunday)"
                echo "step=skip" >> $GITHUB_OUTPUT
              fi
              ;;
            *)
              echo "No scheduled task"
              echo "step=skip" >> $GITHUB_OUTPUT
              ;;
          esac
          
        else
          echo "Push event, running full pipeline"
          echo "step=full" >> $GITHUB_OUTPUT
        fi
    
    - name: Execute pipeline step
      id: execute_pipeline
      if: steps.determine_step.outputs.step != 'skip'
      run: |
        STEP="${{ steps.determine_step.outputs.step }}"
        
        echo "ðŸš€ Executing: $STEP"
        echo "ðŸ•’ UTC: $(date -u '+%Y-%m-%d %H:%M:%S')"
        echo "ðŸ• Karachi: $(TZ='Asia/Karachi' date '+%Y-%m-%d %H:%M:%S')"
        
        case $STEP in
          "data_incremental")
            echo "ðŸ“¥ Running incremental data collection..."
            if [ -f "data_pipeline/collect_historical.py" ]; then
              python data_pipeline/collect_historical.py --incremental --hours=3
            else
              echo "âŒ Script not found!"
            fi
            ;;
            
          "data_full")
            echo "ðŸ“š Running full data collection..."
            if [ -f "data_pipeline/collect_historical.py" ]; then
              python data_pipeline/collect_historical.py
            else
              echo "âŒ Script not found!"
            fi
            ;;
            
          "features")
            echo "ðŸ”§ Running feature engineering..."
            if [ -f "data_pipeline/feature.py" ]; then
              python data_pipeline/feature.py
            else
              echo "âŒ Script not found!"
            fi
            ;;
            
          "train_combined")
            echo "ðŸ¤– Running COMBINED training (your script)..."
            if [ -f "model_training/combinedtraining.py" ]; then
              python model_training/combinedtraining.py
            else
              echo "âŒ combinedtraining.py not found!"
            fi
            ;;
            
          "predictions")
            echo "ðŸ”® Running prediction service..."
            if [ -f "model_training/prediction_service.py" ]; then
              python model_training/prediction_service.py
            else
              echo "âŒ prediction_service.py not found!"
            fi
            ;;
            
          "full")
            echo "ðŸš€ Running FULL PIPELINE..."
            
            echo "1ï¸âƒ£ Collecting data..."
            if [ -f "data_pipeline/collect_historical.py" ]; then
              python data_pipeline/collect_historical.py --incremental --hours=24
            fi
            
            echo "2ï¸âƒ£ Engineering features..."
            if [ -f "data_pipeline/feature.py" ]; then
              python data_pipeline/feature.py
            fi
            
            echo "3ï¸âƒ£ Running combined training..."
            if [ -f "model_training/combinedtraining.py" ]; then
              python model_training/combinedtraining.py
            fi
            
            echo "âœ… Full pipeline completed!"
            ;;
        esac
        
        echo "âœ… Step $STEP completed"
    
    - name: Verify pipeline output
      if: steps.determine_step.outputs.step == 'train_combined' || steps.determine_step.outputs.step == 'full'
      run: |
        echo "ðŸ” Verifying pipeline output..."
        python -c "
        from pymongo import MongoClient
        import os
        from datetime import datetime
        
        client = MongoClient(os.getenv('MONGODB_URI'))
        
        # Check forecasts
        aqi_db = client['aqi_predictor']
        collections = aqi_db.list_collection_names()
        print('ðŸ“Š Available collections:', collections)
        
        # Check key collections
        key_collections = ['ml_forecasts_3day', 'timeseries_forecasts_3day', 'ensemble_forecasts_3day']
        for coll in key_collections:
            if coll in collections:
                count = aqi_db[coll].count_documents({})
                print(f'âœ… {coll}: {count} records')
                
                # Show latest forecast
                latest = aqi_db[coll].find_one(sort=[('created_at', -1)])
                if latest:
                    print(f'   Latest: {latest.get(\"date\", \"N/A\")} - AQI {latest.get(\"predicted_aqi\", \"N/A\")}')
            else:
                print(f'âš ï¸  {coll}: NOT FOUND')
        
        # Check model registry
        if 'aqi_model_registry' in client.list_database_names():
            mr_db = client['aqi_model_registry']
            models = mr_db.model_registry.count_documents({})
            print(f'âœ… Models in registry: {models}')
        else:
            print('âš ï¸  Model registry database not found')
        
        client.close()
        
        print('\\nðŸŽ¯ Your dashboard expects data in:')
        print('   - ml_forecasts_3day')
        print('   - timeseries_forecasts_3day')
        print('   - ensemble_forecasts_3day')
        print('   - aqi_model_registry.model_registry')
        "
    
    - name: Cleanup
      if: always()
      run: |
        echo "ðŸ§¹ Cleaning up..."
        find . -name "*.pyc" -delete
        find . -name "__pycache__" -type d -exec rm -rf {} + 2>/dev/null || true
    
    - name: Summary
      if: always()
      run: |
        echo "ðŸ“Š PIPELINE SUMMARY"
        echo "Run ID: ${{ github.run_id }}"
        echo "Step: ${{ steps.determine_step.outputs.step }}"
        echo "Status: ${{ job.status }}"
        echo "Time: $(TZ='Asia/Karachi' date '+%Y-%m-%d %H:%M:%S %Z')"
